---
title: "Macbook本地部署DeepSeek，其他系统类似"
date: 2025-02-01
permalink: /posts/2025/02/blog-post-1/
tags:
- deepseek
- LLM
---

本地部署完成后的效果如下图，整体与chatgpt类似，只是模型在本地推理。
![](https://borninfreedom.github.io/images/2025/02/ollama/7.png)


我们在本地部署主要使用两个工具：
1. [ollama](https://ollama.com)
2. [open-webui](https://github.com/open-webui/open-webui)

ollama是在本地管理和运行大模型的工具，可以直接在terminal里和大模型对话。open-webui是提供一个类似chatgpt的网页，相比terminal更加方便和直观一些。open-webui可自动检测ollama已经下载的模型，直接选择使用即可。两者搭配使用。


使用ollama，我们可以不用配置开发环境，也不需要写推理代码，使用起来类似conda或者docker，直接执行指令来运行某个模型就可以。比如想用deepseek模型，就执行`ollama run deepseek-r1`，想用llama模型，就执行`ollama run llama3.3`。下面具体介绍一下ollama和安装方法。

Ollama是一个开源的大型语言模型服务工具，以下是对它的具体介绍：
# ollama介绍

### 特点
- **本地部署**：专注于在本地机器上便捷部署和运行大型语言模型，用户可在自己设备上运行模型，保护数据隐私，无需担心数据发送到云端的安全风险。
- **多系统支持**：支持Mac、Linux和Windows等多种操作系统，用户在不同平台上都能方便地安装使用。
- **多模型支持**：支持Deepseek-r1、Llama、Falcon、Qwen2、Phi3、Gemma2等多种流行的LLM模型，用户可按需选择，一键运行。
- **易于使用**：提供直观的命令行界面，操作简单，上手容易，降低了使用门槛。
- **可扩展性**：支持自定义配置，用户能根据自身硬件环境和模型需求进行优化，还可通过安装插件增加新功能。
- **开源**：代码完全开放，用户可自由查看、修改和分发，活跃的开发者社区也会提供问题解答和持续改进。
- **API支持**：提供简洁的API，方便开发者创建、运行和管理大型语言模型实例，轻松将其集成到各种应用程序中。
- **预构建模型库**：包含一系列预先训练好的模型，用户可直接选用，无需从头训练或自行寻找模型源。
- **模型导入与定制**：支持从特定平台导入已有的大型语言模型，兼容PyTorch或Safetensors深度学习框架，方便用户集成自有模型。

### 功能
- **自动硬件加速**：能自动识别并充分利用系统中的最优硬件资源，如NVIDIA GPU、AMD GPU，或利用CPU的AVX、AVX2指令集等，实现针对性优化，确保AI模型高效运行。
- **无需虚拟化**：无需搭建虚拟机或配置复杂软件环境，可直接开始AI项目开发，简化流程。
- **常驻API**：在后台运行，可将强大的AI功能与项目无缝对接，无需额外复杂设置，方便将AI功能整合到应用中。

### 应用场景
- **开发和测试**：开发人员可以使用Ollama在本地快速搭建语言模型环境，用于开发新的语言相关的应用程序。
- **个人学习和研究**：对于研究自然语言处理的学者或者对语言模型感兴趣的个人来说，Ollama提供了一个方便的实验平台。
- **文本生成**：可用于生成各种文本内容，如新闻文章、博客文章、诗歌、代码等。
- **翻译**：能够将文本从一种语言翻译成另一种语言。
- **问答**：可以用于回答用户提出的各种问题。

# ollama安装

直接访问其官网[ollama](https://ollama.com)，点击Download下载安装即可。傻瓜式安装。

安装完成后，ollama会在后台作为服务运行，这时候我们只需要重启一下terminal，然后运行想要的模型即可。

ollama所有支持的模型都可以从这个网站获得运行指令和详细介绍[ollama models](https://ollama.com/search)。

![](https://borninfreedom.github.io/images/2025/02/ollama/1.png)

比如我们想用tinyllama模型，就直接执行`ollama run tinyllama`。
![](https://borninfreedom.github.io/images/2025/02/ollama/2.png)

类似docker image，经过一个pull的过程后，就可以使用了。

如果想使用deepseek-r1模型，直接运行`ollama run deepseek-r1`即可。
![](https://borninfreedom.github.io/images/2025/02/ollama/4.png)


现在只能在terminal上使用大模型，略显不方便。如果有个web界面就好了。open-webui就是和ollama深度集成的webui界面，类似chatgpt的。而且不需要额外做什么，安装ollama后，open-webui会自动检测已经安装的模型，选择对应模型使用即可。

# open-webui介绍

Open-WebUI是一个可扩展、功能丰富且用户友好的自托管AI平台，
在其[官方github](https://github.com/open-webui/open-webui)的介绍上，就注明了与ollama可以集成。
![](https://borninfreedom.github.io/images/2025/02/ollama/3.png)

以下是具体介绍：

### 特点
- **部署便捷**：可使用Docker或Kubernetes（kubectl、kustomize或helm）进行无缝安装，支持ollama和cuda tagged镜像，轻松搭建AI环境。
- **集成能力强**：能与Ollama、OpenAI兼容的API集成，还可自定义OpenAI API的URL，连接到LM Studio、Groq Cloud、Mistral、Open Router等。
- **安全与权限管理精细**：支持基于角色的访问控制（RBAC），管理员可创建详细的用户角色和权限，确保只有授权人员能访问Ollama及相关敏感信息，且模型创建/拉取权限专属于管理员。
- **多端适配好**：采用响应式设计，在桌面PC、笔记本电脑和移动设备上都能提供无缝的使用体验；还提供适用于移动设备的渐进式Web应用程序（PWA），可在localhost上离线访问，提供类似原生应用的界面。
- **多语言支持**：具备国际化（i18n）支持，用户可使用自己熟悉的语言操作平台，且项目方积极寻求贡献者来扩展支持的语言种类。

### 功能
- **文本交互增强**：支持完整的Markdown和LaTeX功能，便于用户进行结构化文档创建和数学表达式输入；还支持提示预设，可通过聊天输入中的命令立即访问预设提示，也可通过Open WebUI社区集成轻松导入提示。
- **多媒体交互**：支持免提语音/视频通话，使聊天环境更具动态性和互动性；集成图像生成功能，可使用AUTOMATIC1111 API（本地）、ComfyUI（本地）和OpenAI的DALL-E（外部）等生成图像，丰富聊天体验。
- **模型管理与操作**：可通过Web UI轻松创建Ollama模型，包括创建和添加自定义角色/代理、自定义聊天元素、导入模型等；支持GGUF文件模型创建，能直接从Web UI上传GGUF文件，也可选择从计算机上传或从Hugging Face下载。
- **代码与工具集成**：提供原生Python函数调用工具，在工具工作区中有内置的代码编辑器支持，用户可添加纯Python函数，实现与LLMs的无缝集成；支持Pipelines插件框架，可将自定义逻辑和Python库集成到Open WebUI中。
- **搜索与浏览**：集成本地RAG，支持将文档直接加载到聊天中或添加到文档库，通过`#`命令访问；支持网页搜索，可使用SearxNG、Google PSE、Brave Search等多种搜索引擎，并将结果注入聊天；可通过`#`命令+URL将网站集成到聊天中。

### 应用场景
- **AI开发与研究**：为开发者和研究人员提供了一个便捷的平台，方便他们快速搭建AI模型的测试和开发环境，进行模型的调试、优化等工作，加速AI项目的研发进程。
- **智能客服与聊天机器人**：可集成各种语言模型，构建智能客服系统或聊天机器人，为用户提供快速、准确的信息解答和服务支持，提升客户服务体验。
- **内容创作与辅助**：帮助内容创作者生成文章、故事、诗歌等各种文本内容，提供创作灵感和思路，提高创作效率和质量。
- **教育与培训**：在教育领域可用于构建智能辅导系统，根据学生的问题和学习情况提供个性化的解答和指导；也可作为培训工具，帮助学员更好地理解和掌握知识。


# open-webui安装

在terminal直接执行`pip install open-webui`即可。安装完成后，执行`open-webui serve`。

![](https://borninfreedom.github.io/images/2025/02/ollama/5.png)

不过经过我测试，在MacBook的safari浏览器上，输入http://0.0.0.0:8080不行，**127.0.0.1:8080是可以的**。

![](https://borninfreedom.github.io/images/2025/02/ollama/6.png)

![](https://borninfreedom.github.io/images/2025/02/ollama/7.png)













