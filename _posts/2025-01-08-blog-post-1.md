---
title: "mac配置stable diffusion以及模型出图优化"
date: 2025-01-08
permalink: /posts/2025/01/blog-post-2/
tags:
  - stable diffusion
  - mac
---

# 1. 基础stable diffusion webui安装

使用的工程是[stable-diffusion-webui](https://github.com/AUTOMATIC1111/stable-diffusion-webui)，直接clone下来即可。

然后创建一个conda环境，python为3.9

激活conda环境后，执行`./webui.sh`即可。脚本会自动安装必要的包，然后启动网页。

![](https://borninfreedom.github.io/images/2025/01/sd/1.png)

默认有一个sd v1.5的checkpoint pth。我们输入cat或者dog，点击generate，能够正常生成一副怪怪的图片就可以了。这时候，在后台，terminal中会有一系列log显示：

![](https://borninfreedom.github.io/images/2025/01/sd/2.png)


# 2. 模型更换

直接使用默认的stable diffusion webui只有一个sd v1.5的 checkpoint，出图效果一般。我们测试几张图，分别使用A dog，A cat， A Nikon camera。sd v1.5的出图是下面的：

![](https://borninfreedom.github.io/images/2025/01/sd/3.png)

网络上有很多提供不同类模型的网站。这里推荐[c站](https://civitai.com),然后切换到Models标签，使用过滤按钮来选择Checkpoint。

![](https://borninfreedom.github.io/images/2025/01/sd/4.png)


我们找到一个喜欢的模型，比如这个
![](https://borninfreedom.github.io/images/2025/01/sd/7.png)

点击下载按钮下载checkpoint即可。然后将下载的checkpoint（以.safetensors结尾）放到stable-diffusion-webui的工程的models/Stable-diffusion文件夹里面.

![](https://borninfreedom.github.io/images/2025/01/sd/8.png)

回到sd webui上，点击一下checkpoint的刷新按钮，然后选择刚刚新添加的checkpoint即可。

![](https://borninfreedom.github.io/images/2025/01/sd/9.png)

我们还是用旧的指令，看一下生成的图

![](https://borninfreedom.github.io/images/2025/01/sd/10.png)

相比sd v1.5的模型，生成的图确实真实不少，尤其是尼康相机。

在civitai的网站，我们下载模型的时候，有很多model types，他们具有不同的作用，我们在优化出图质量时，要根据不同的需求来下载对应的模型。

![](https://borninfreedom.github.io/images/2025/01/sd/11.png)

我们先大体说一下不同model type的区别：


Stable Diffusion 是一个生成式模型框架，支持多种扩展和调整方式：

---

### 1. **Checkpoint**
- **定义**: Checkpoint 是指模型的权重文件，通常以 `.ckpt` 或 `.safetensors` 格式存储。
- **作用**: 包含了训练完成后的模型的全部参数，用于生成图像。
- **类型**:
  - **基础模型**: 例如 Stable Diffusion v1.5 或 v2.x。
  - **微调模型**: 针对特定风格或任务微调过的模型，如动漫风格、现实风格等。
- **使用场景**: 根据需求加载不同的 checkpoint 来生成符合特定风格的图像。

---

### 2. **Embedding (Textual Inversion Embedding)**
- **定义**: 一种用于扩展文本提示词（Prompt）能力的小型模型文件，通常以 `.pt` 或 `.bin` 格式存储。
- **作用**: 将特定风格、人物或主题压缩到一个短语（例如 `<style_A>`）中，增强生成能力。
- **特点**:
  - 对基础模型影响较小，加载时只需简单附加。
  - 文件体积较小，通常只有几 MB。
- **使用场景**: 用于生成特定人物或风格的图像，例如将现实中的人物融入生成。

---

### 3. **LoRA (Low-Rank Adaptation)**
- **定义**: 一种轻量级微调方法，主要用于减少模型微调的资源消耗。
- **作用**: 将模型的某些权重低秩分解，只需保存更新部分（通常较小）。
- **优点**:
  - 不需要修改原始模型。
  - 占用存储空间小，加载快速。
- **使用场景**: 用于快速适配特定风格、主题或领域，例如生成某种艺术风格的图像。

---

### 4. **Dora**
- **定义**: 在 Stable Diffusion 生态中，Dora 通常指与 Dora Models 相关的扩展工具或轻量级微调模块。
- **作用**: 类似于 LoRA 的小型插件或模型扩展，具体细节因应用而异。
- **备注**: Dora 较少被单独提及，可能需要结合实际工具链确认具体用途。

---

### 5. **ControlNet**
- **定义**: ControlNet 是一种扩展模块，用于在生成图像时添加额外的控制条件。
- **作用**: 为生成过程添加更多输入（如边缘检测、深度图、姿态骨架等），从而精确控制输出图像的结构或内容。
- **特点**:
  - 可以将特定的外部信息（如草图）与提示词结合使用。
  - 提高生成的灵活性和一致性。
- **使用场景**: 在需要对生成图像的结构严格控制时非常有用，例如生成与草图匹配的图像。

---

### 6. **VAE (Variational AutoEncoder)**
- **定义**: Variational AutoEncoder 是 Stable Diffusion 中用于解码潜在空间（Latent Space）的组件。
- **作用**: 将潜在空间的向量解码为可视化图像。
- **特点**:
  - 高质量的 VAE 可以提升生成图像的细节和颜色表现。
  - 通常可以单独替换 VAE 以优化模型输出。
- **使用场景**: 用于提升图像生成质量，特别是在需要更高分辨率或更多细节的任务中。

---

### 7. **Workflows**
- **定义**: Workflows 是生成图像的一系列步骤或流水线，通常由多个模型、插件或条件组合而成。
- **作用**: 将复杂的生成流程模块化，例如结合文本提示词、ControlNet、LoRA 和 VAE 的多步骤生成。
- **使用场景**: 自动化或批量处理任务，适合需要复合功能的复杂生成需求。

---

### 总结
| 名称       | 文件类型        | 功能特点                                               | 使用场景                         |
|------------|-----------------|------------------------------------------------------|----------------------------------|
| Checkpoint | `.ckpt` / `.safetensors` | 基础或微调模型权重，控制整体风格和质量                   | 通用生成                         |
| Embedding  | `.pt` / `.bin`  | 增强 Prompt 表达能力，加入特定风格或主题                 | 特定风格或角色生成               |
| LoRA       | `.safetensors`  | 轻量级微调模型，快速加载附加风格或任务                   | 灵活适配多种风格                 |
| Dora       | 模型扩展模块     | 类似 LoRA 的插件，具体功能依工具而异                     | 小范围功能扩展                   |
| ControlNet | `.ckpt` / `.safetensors` | 增加对生成图像结构的控制                                 | 精确生成结构化图像               |
| VAE        | `.ckpt` / `.safetensors` | 提升解码质量，增强图像细节                               | 高质量输出                       |
| Workflows  | 流程配置文件     | 多模型、多模块的协同生成                                 | 自动化复杂生成任务               |


# 3. webui相关扩展安装

## 3.1 中文包

在搜索框搜Hans，如果没有安装的话，最下面红框的地方，就会有简体中文的选项，点击install即可。

![](https://borninfreedom.github.io/images/2025/01/sd/12.png)

然后再安装一个bilingual，便于查看原始的英文是什么。

![](https://borninfreedom.github.io/images/2025/01/sd/13.png)

然后应用下载的中文包

![](https://borninfreedom.github.io/images/2025/01/sd/15.png)
![](https://borninfreedom.github.io/images/2025/01/sd/16.png)
![](https://borninfreedom.github.io/images/2025/01/sd/17.png)

最后点击上图右侧的 reload UI 按钮。

也可以设置双语。还是在上图的设置上，把Localization改为无，然后打开

![](https://borninfreedom.github.io/images/2025/01/sd/18.png)
![](https://borninfreedom.github.io/images/2025/01/sd/19.png)


## 3.2 历史生成图保存插件

插件地址为：https://github.com/zanllp/sd-webui-infinite-image-browsing.git

![](https://borninfreedom.github.io/images/2025/01/sd/20.png)


然后回到已安装，重启生效即可。
![](https://borninfreedom.github.io/images/2025/01/sd/21.png)

![](https://borninfreedom.github.io/images/2025/01/sd/22.png)

我们点击文生图，就可以看到之前所有用文生图生成的照片了。
![](https://borninfreedom.github.io/images/2025/01/sd/23.png)

也可以点击图片右上角的三点，将其发送到图生图。
![](https://borninfreedom.github.io/images/2025/01/sd/24.png)


## 3.3 主题插件

还是在extension上面搜索lobe安装

![](https://borninfreedom.github.io/images/2025/01/sd/25.png)

现在的主题就要美观很多，而且对于checkpoint我们可以添加一个封面，更好区分不同的checkpoint类型。

![](https://borninfreedom.github.io/images/2025/01/sd/26.png)

例如我们前面用过的CyberRealistic checkpoint，我们这里只有一个checkpoint的名字，没有他的具体的图片展示能让我们一下子就能看出来模型的效果。

![](https://borninfreedom.github.io/images/2025/01/sd/27.png)

下面我们看一下怎么添加他的效果图片。

我们还是回到C站，找到CyberRealistic，我们随便找一个他的展示图片。

![](https://borninfreedom.github.io/images/2025/01/sd/28.png)

然后将其保存到和checkpoint同样路径，命名为同名

![](https://borninfreedom.github.io/images/2025/01/sd/29.png)

再次回到webui，点一下checkpoint的刷新，就可以看到效果图片显示在checkpoint上面了。

![](https://borninfreedom.github.io/images/2025/01/sd/30.png)





