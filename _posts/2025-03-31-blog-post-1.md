---
title: "jetson orin nano super AI模型部署之路（四）YOLOV10部署"
date: 2025-03-28
permalink: /posts/2025/03/blog-post-8/
tags:
-  jetson
-  部署
---

我们先直接拿一篇paper中的截图来做测试。

![](https://borninfreedom.github.io/images/2025/03/yolo/1.png)

在terminal可以看到检测的结果：其中检测到了12个人，1辆车等，以及前后处理和模型推理所用的时间。
![](https://borninfreedom.github.io/images/2025/03/yolo/2.png)

我们还是使用我们在“jetson orin nano super AI模型部署之路（二）保姆级最好用AI环境配置”中介绍的docker环境为基础，在这篇文章中，我们介绍了dustynv/nanoowl:r36.4.0这个docker image，里面包含了jetson的pytorch、tensorrt等常用的组件。

我们启动一个container。

```bash
sudo docker run --runtime nvidia --gpus all --net host --ipc host -it --name yolo  -v /home:/home dustynv/nanoow:r36.4.0
```

然后我们拉取yolov10的代码，并且进入直接run即可：

```bash
git clone https://github.com/THU-MIG/yolov10.git
cd yolov10
mkdir weights
python3 app.py
```

这个过程如果缺什么包，再根据需要安装即可。注意如果想在jetson上运行代码，然后在局域网内其他计算机访问jetson来运行，需要修改代码，在launch的时候，加上server_name="0.0.0.0"，以便其他机器可以访问到。
```python
if __name__ == '__main__':
    gradio_app.launch(server_name="0.0.0.0")
```



