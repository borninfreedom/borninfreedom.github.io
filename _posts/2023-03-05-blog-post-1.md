---
title: "使用ncnn在树莓派4B上部署nanoDet网络(12fps)"
date: 2023-03-05
permalink: /posts/2023/03/blog-post-1/
tags:
  - nanoDet
  - 树莓派
  - 模型部署与落地
---

**1. 背景：**

在机器人的应用中，目标检测是一个重要的课题。深度学习的快速发展，在检测的效果方面对比大多数传统检测算法，都有明显的优势。但是将深度学习模型部署到端侧设备上，实现高效的推理，同样是一个问题很多的领域。

在机器人的主控中，树莓派和Jetson系列单板机被使用较多。这篇blog以树莓派4b为例，展示将深度学习模型部署到低算力平台的方法。

与深度学习在GPU上的推理不同，为了实现高效推理，一般都会选择使用推理框架，而不是直接使用python的推理代码进行推理。在CPU侧，常用的推理框架有ncnn、mnn、openvino等；在GPU侧，有tensorrt；高通在htp上，同样有snpe和qnn等推理框架。**本blog使用树莓派的CPU进行推理，使用ncnn作为推理框架。**

**2. 效果：**

如果所示的两个场景，在被检测目标较为密集的场合，检测算法也能达到11fps，且识别率很高。
![](https://borninfreedom.github.io/images/2023/03/nanodetfps0.png)

![](https://borninfreedom.github.io/images/2023/03/nanodetfps1.png)

