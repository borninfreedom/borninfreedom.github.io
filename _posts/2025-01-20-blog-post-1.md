---
title: "AiISP论文Learning to See in the Dark解读"
date: 2025-01-20
permalink: /posts/2025/01/blog-post-6/
tags:
- AIISP
---

论文地址：[Learning to See in the Dark](https://arxiv.org/abs/1805.01934)

![](https://borninfreedom.github.io/images/2025/01/dark/1.png)
图1. 利用卷积网络进行极微光成像。黑暗的室内环境。相机处的照度小于0.1勒克斯。索尼α7S II传感器曝光时间为1/30秒。(a) 相机在ISO 8000下拍摄的图像。(b) 相机在ISO 409600下拍摄的图像。该图像存在噪点和色彩偏差。(c) 我们的卷积网络应用于(a)中原始传感器数据所生成的图像。 

# 摘要

由于光子数量少和信噪比低，低光照成像颇具挑战性。短曝光图像存在噪声问题，而长曝光会导致图像模糊，且往往不切实际。人们已经提出了各种去噪、去模糊和增强技术，但在诸如夜间视频帧率成像等极端条件下，它们的效果有限。为推动基于学习的低光照图像处理流程的发展，我们引入了一个原始短曝光低光照图像数据集，以及相应的长曝光参考图像。利用这个数据集，我们基于全卷积网络的端到端训练，开发了一个处理低光照图像的流程。该网络直接对原始传感器数据进行处理，取代了许多传统的图像处理流程，而传统流程在处理此类数据时往往效果不佳。我们在新数据集上取得了有前景的结果，分析了影响性能的因素，并指出了未来工作的方向。 

# 1. 引言
噪声存在于任何成像系统中，而在低光照环境下，它让成像变得尤其具有挑战性。高感光度（ISO）可用于提高亮度，但同时也会放大噪声。可以采用诸如缩放或直方图拉伸之类的后处理方法，但由于光子数量少，这些方法无法解决低信噪比（SNR）的问题。在低光照环境中有一些物理方法来提高信噪比，包括增大光圈、延长曝光时间以及使用闪光灯。但这些方法各有其典型的缺点。例如，延长曝光时间可能会因相机抖动或物体移动而导致图像模糊。

低光照下的快速成像难题在计算摄影领域广为人知，但至今仍未得到解决。研究人员已提出了用于低光照图像去噪、去模糊和增强的技术[34, 16, 42]。这些技术通常假定图像是在光线稍暗且噪声水平适中的环境中拍摄的。相比之下，我们关注的是在光照严重受限（如月光下）且曝光时间短（理想情况下为视频帧率）的极微光成像。在这种情况下，传统的相机处理流程会失效，图像必须从原始传感器数据中重建。

图1展示了我们的设定。环境极其黑暗：相机处的光照不足0.1勒克斯。曝光时间设置为1/30秒，光圈为f/5.6。即使使用通常被认为较高的ISO 8000，尽管索尼全画幅传感器的感光度很高，相机拍摄出的图像基本上仍是黑色的。当ISO达到409,600（这远远超出了大多数相机的能力范围）时，场景内容可辨，但图像暗淡、有噪声，且颜色失真。正如我们将展示的，即使是最先进的去噪技术[32]也无法去除此类噪声，也无法解决色彩偏差问题。另一种方法是使用连拍图像[24, 14]，但连拍对齐算法在极微光条件下可能会失效，而且连拍处理流程并非为视频拍摄而设计（例如，由于连拍中使用了“幸运成像”技术）。

我们提出了一种新的图像处理流程，通过数据驱动的方法来应对极微光摄影的挑战。具体而言，我们训练深度神经网络，以学习针对低光照原始数据的图像处理流程，包括颜色转换、去马赛克、降噪和图像增强。该流程采用端到端的训练方式，以避免传统相机处理流程在这种情况下出现的噪声放大和误差累积问题。

现有的大多数低光照图像处理方法都是在合成数据或没有真实参考的真实低光照图像上进行评估的。据我们所知，目前尚无公开数据集可用于使用多样化的真实世界数据和真实参考来训练和测试快速低光照图像处理技术。因此，我们收集了一个新的数据集，其中包含在低光照条件下快速曝光拍摄的原始图像。每张低光照图像都有对应的长曝光高质量参考图像。我们在新数据集上取得了有前景的结果：低光照图像放大倍数高达300倍，同时成功实现了降噪和正确的颜色转换。我们系统地分析了该流程的关键要素，并讨论了未来的研究方向。 

---

lux（勒克斯）是一个用于衡量光照强度的国际单位制导出单位，以下是关于它的详细解释：

- **定义**：勒克斯被定义为每平方米的流明数，即\(1\)勒克斯等于\(1\)流明/平方米（\(1 lx = 1 lm/m^{2}\)）。流明是光通量的单位，它表示光源在单位时间内发出的光的总量。勒克斯主要用于描述被照表面所接收到的光的强度，也就是表示某一区域表面被照亮的程度。

- **实际应用场景**
    - **室内照明设计**：在设计办公室、教室、商场等室内空间的照明时，需要根据不同的功能和活动要求，确保达到合适的勒克斯数值。例如，一般办公室的桌面照明通常要求达到300 - 500勒克斯，以保证工作人员能够清晰地看到文件和操作设备；而卧室的照明可能只需要100 - 200勒克斯，营造出较为柔和舒适的氛围。
    - **道路照明**：道路照明的亮度也以勒克斯为单位来衡量。城市主干道的照明一般需要达到15 - 20勒克斯左右，以确保车辆和行人在夜间能够安全通行；而小区内的道路照明可能相对较低，在5 - 10勒克斯左右。
    - **摄影领域**：摄影师在拍摄时需要考虑环境的勒克斯值，以确定合适的曝光参数。在低光照环境下，如光照强度低于1勒克斯的极暗环境，拍摄会变得非常困难，需要使用高感光度、长曝光时间或辅助照明设备来获得清晰的图像；而在阳光充足的户外，光照强度可能达到10000勒克斯以上，此时需要注意控制曝光，避免照片过曝。

- **与其他光照单位的关系**：在光照度量中，还有其他一些单位，如坎德拉（cd）是发光强度的单位，它描述的是光源在特定方向上的发光能力；而英尺烛光（fc）是英制单位制中的光照强度单位，\(1\)英尺烛光等于\(1\)流明/平方英尺，与勒克斯的换算关系为\(1\)英尺烛光约等于\(10.764\)勒克斯。

---

前面提到的“幸运成像”技术，“lucky imaging”即幸运成像，是一种主要用于天文摄影的成像技术，以下是具体介绍：
- **技术原理**：采用多次短时间（100毫秒或以下）曝光的方式，然后从大量拍摄的照片中挑选出受大气影响最少的部分照片，再对这些照片进行移动和叠加，最终生成一张图像。由于大气湍流等因素会严重影响地基望远镜的成像质量，长时间曝光会使图像变得模糊，而幸运成像通过选取受大气干扰小的短曝光图像进行合成，能有效减少大气噪声的影响，获得清晰度较高的图像。
- **应用实例**：在拍摄天体时，可能会拍摄高达50000张照片，然后从中筛选出受大气扰动影响最小的部分用于最终图像的合成。英国剑桥大学和美国加州理工学院的天文学家曾将该技术应用于美国加州200英尺口径的Palomar望远镜，得到了25000光年外的M13球状星团以及猫眼星云（Cat's Eye Nebula）的图像，其分辨率约是哈勃的两倍。

---


# 2. 相关工作
低光照图像的计算处理在文献中已有广泛研究。我们简要回顾一下现有方法。
- **图像去噪**：图像去噪是底层视觉领域一个发展较为成熟的课题。已提出了许多方法，运用了诸如全变分 [36]、小波域处理 [33]、稀疏编码 [9, 28]、核范数最小化 [12] 以及三维变换域滤波（BM3D）[7] 等技术。这些方法通常基于特定的图像先验知识，如平滑性、稀疏性、低秩性或自相似性。研究人员也探索了深度网络在去噪方面的应用，包括堆叠稀疏去噪自编码器（SSDA）[39, 1]、可训练非线性反应扩散（TNRD）[6]、多层感知器 [3]、深度自编码器 [26] 以及卷积网络 [17, 41]。当在特定噪声水平下进行训练时，这些数据驱动的方法能够与诸如BM3D和稀疏编码等最先进的经典技术相媲美。不幸的是，大多数现有方法都是在合成数据上进行评估的，比如添加了高斯噪声或椒盐噪声的图像。最近一项针对真实数据的细致评估发现，在真实图像上BM3D的表现优于更新的技术 [32]。联合去噪与去马赛克也得到了研究，包括近期使用深度网络的工作 [15, 10]，但这些方法是在合成的拜耳模式和合成噪声上进行评估的，而非在极微光条件下采集的真实图像。
  
除了单图像去噪，多图像去噪也得到了关注，并且由于从场景中收集到了更多信息，它能取得更好的效果 [31, 23, 19, 24, 14, 29]。特别是，Liu等人 [24] 以及Hasinoff等人 [14] 提出对同一场景的连拍图像进行去噪。虽然这些流程通常很有效，但可能会很复杂，涉及参考图像选择（“幸运成像”）以及图像间的密集对应估计。我们专注于一条互补的研究路线，探究单图像处理能达到何种程度。
- **低光照图像增强**：多种技术已被应用于增强低光照图像的对比度。一种经典选择是直方图均衡化，它平衡了整个图像的直方图。另一种广泛使用的技术是伽马校正，它在压缩亮像素的同时增加暗区域的亮度。更先进的方法会进行更全面的全局分析和处理，例如使用逆暗通道先验 [8, 29]、小波变换 [27]、Retinex模型 [30] 以及光照图估计 [13]。然而，这些方法通常假定图像已经很好地呈现了场景内容。它们没有对图像噪声进行明确建模，并且通常将现成的去噪方法作为后处理步骤。相比之下，我们考虑的是极微光成像，其存在严重的噪声和色彩失真，超出了现有增强流程的适用条件。
- **含噪图像数据集**：尽管有许多关于图像去噪的研究，但大多数现有方法都是在合成数据上进行评估的，例如添加了高斯噪声或椒盐噪声的干净图像。RENOIR数据集 [2] 被提出用于对真实含噪图像的去噪进行基准测试。然而，正如文献 [32] 所报道的，RENOIR数据集中的图像对存在空间错位问题。连拍图像已被用于在低光照条件下去噪 [24]，但相关数据集并不包含可靠的真实参考数据。谷歌HDR + 数据集 [14] 并非针对极微光成像：数据集中的大多数图像是在白天拍摄的。最近的达姆施塔特噪声数据集（DND）[32] 旨在满足去噪领域对真实数据的需求，但这些图像也是在白天拍摄的，并不适用于低光照图像处理的评估。据我们所知，目前没有包含原始低光照图像及相应真实参考的公开数据集。因此，我们收集了这样一个数据集，以支持该领域系统的可重复性研究。 

![](https://borninfreedom.github.io/images/2025/01/dark/t1.png)
表1. “暗光可视”（SID）数据集包含5094张原始短曝光图像，每张图像都有一张对应的长曝光参考图像。这些图像由两台相机采集（上下排列）。从左至右依次为：输入图像与参考图像的曝光时间比、滤镜阵列、输入图像的曝光时间，以及每种条件下的图像数量。 

![](https://borninfreedom.github.io/images/2025/01/dark/2.png)
图2. “暗光可视”（SID）数据集的示例图像。前两行是室外图像，后几行是室内图像。前面展示的是长曝光参考（真实）图像，后面展示的是短曝光输入图像（基本为黑色）。相机处的照度通常在室外为0.2到5勒克斯，在室内为0.03到0.3勒克斯。 


# 3. 暗光可视数据集
我们收集了一个新的数据集，用于训练和基准测试原始低光照图像的单图像 处理。“暗光可视”（SID）数据集包含5094张原始短曝光图像，每张都有 对应的长曝光参考图像。需要注意的是，多张短曝光图像可以对应同一张长 曝光参考图像。例如，我们收集了短曝光图像序列来评估连拍去噪方法。序 列中的每张图像都被视为一张独特的低光照图像，因为每张这样的图像都包 含真实的成像伪影，对训练和测试很有用。SID中不同的长曝光参考图像数 量为424张。

该数据集包含室内和室外图像。室外图像通常在夜间月光或路灯下拍摄。 室外场景中相机处的照度一般在0.2勒克斯到5勒克斯之间。室内图像的光照 更暗，是在关闭普通灯光、专门设置微弱间接照明的封闭房间内拍摄的。室 内场景中相机处的照度一般在0.03勒克斯到0.3勒克斯之间。

输入图像的曝光时间设置在1/30秒到1/10秒之间。相应的参考（真实）图 像是以长100到300倍的曝光时间拍摄的，即10到30秒。由于参考图像的曝 光时间必然较长，数据集中的所有场景都是静态的。数据集总结见表1。图2 展示了一小部分参考图像样本。每个条件下约20%的图像被随机选出来组成 测试集，另外10%被选作验证集。

图像是使用两台相机拍摄的：索尼α7S II和富士X - T2。这两台相机的传 感器不同：索尼相机配备全画幅拜耳传感器，富士相机配备APS - C规格的 X - Trans传感器。这有助于在不同滤镜阵列产生的图像上评估低光照图像 处理流程。索尼图像的分辨率为4240×2832，富士图像的分辨率为6000×4000。 索尼相机使用了两种不同的镜头来收集图像。

相机安装在稳固的三脚架上。我们使用无反相机以避免因反光镜翻动产 生振动。在每个场景中，光圈、ISO、对焦和焦距等相机设置都经过调整， 以最大化参考（长曝光）图像的质量。拍摄完长曝光参考图像后，通过手机 远程应用程序将曝光时间缩短100到300倍，拍摄一系列短曝光图像。在拍 摄长曝光和短曝光图像之间，不会触碰相机。我们收集短曝光图像序列，以 便与理想的连拍成像流程进行比较，后者得益于完美的对齐。

长曝光参考图像可能仍包含一些噪声，但感知质量足够高，可作为真实 参照。我们的目标应用场景是在低光照条件下生成感知效果良好的图像，而 不是彻底去除所有噪声或最大化图像对比度。 

![](https://borninfreedom.github.io/images/2025/01/dark/3.png)

# 4. 方法
## 4.1 流程
从成像传感器获取原始数据后，传统的图像处理流程会应用一系列模块，如白平衡、去马赛克、去噪、锐化、色彩空间转换、伽马校正等。这些模块通常针对特定相机进行调校。姜等人[18]提出使用大量局部的、线性的以及经过学习的（L3）滤波器，来近似现代消费级成像系统中复杂的非线性流程。然而，无论是传统流程还是L3流程，都无法成功应对快速低光照成像，因为它们无法处理极低的信噪比。哈西诺夫等人[14]描述了一种用于智能手机相机的连拍成像流程。该方法通过对齐和融合多张图像能产生不错的效果，但会引入一定程度的复杂性，例如由于需要进行密集的对应关系估计，并且可能不容易扩展到视频拍摄，比如因使用了“幸运成像”技术。

我们提议使用端到端学习来对快速低光照图像进行直接的单图像 处理。具体而言，我们训练一个全卷积网络（FCN）[22, 25]来执行整个图像处理流程。近期研究表明，纯全卷积网络可以有效地表示许多图像处理算法[40, 5]。我们受此启发，探究将这种方法应用于极微光成像。我们不是对传统相机处理流程生成的普通sRGB图像进行操作，而是对原始传感器数据进行处理。

图3（b）展示了所提出流程的结构。对于拜耳阵列，我们将输入数据整合为四个通道，并相应地在每个维度上将空间分辨率降低一半。对于X - Trans阵列（图中未展示），原始数据以6×6的块排列；我们通过交换相邻元素将其整合为9个通道，而非36个通道。我们减去黑电平，并按所需的放大倍数（例如100倍或300倍）对数据进行缩放。经过整合和放大的数据被输入到全卷积网络中。输出是一个具有一半空间分辨率的12通道图像。这个尺寸减半的输出由一个亚像素层进行处理，以恢复原始分辨率[37]。

经过初步探索，我们聚焦于构成流程核心的全卷积网络的两种通用结构：一种是最近用于快速图像处理的多尺度上下文聚合网络（CAN）[5]，另一种是U-net[35]。其他研究探索了残差连接[20, 34, 41]，但在我们的场景中，我们并未发现其有帮助，这可能是因为我们的输入和输出采用不同的色彩空间表示。影响我们选择架构的另一个考虑因素是内存消耗：我们选择了能够在GPU内存中处理全分辨率图像（例如分辨率为4240×2832或6000×4000）的架构。因此，我们避免了需要处理小图像块并重新组合它们的全连接层[26]。我们默认的架构是U-net[35]。

放大倍数决定了输出图像的亮度。在我们的流程中，放大倍数在外部设置，并作为输入提供给流程，类似于相机中的ISO设置。图4展示了不同放大倍数的效果。用户可以通过设置不同的放大因子来调整输出图像的亮度。在测试时，该流程执行盲去噪和颜色转换。网络直接在sRGB空间中输出处理后的图像。 

![](https://borninfreedom.github.io/images/2025/01/dark/4.png)
图4. 放大因子对“暗光可视”（SID）数据集中一张室内图像局部区域的影响（索尼100倍放大子集）。放大因子作为外部输入提供给我们的处理流程，类似于相机中的ISO设置。放大因子越高，图像越亮。本图展示了我们的处理流程在不同放大因子下的输出结果。 

## 4.2 训练
我们使用L1损失和Adam优化器[21]从零开始训练网络。在训练过程中，网络的输入是短曝光图像的原始数据，而真实标签是相应的在sRGB色彩空间中的长曝光图像（由原始图像处理库libraw处理）。我们针对每台相机训练一个网络。在训练和测试中，放大倍数均设置为输入图像与参考图像之间的曝光差异（例如100倍、250倍或300倍）。在每次迭代中，我们随机裁剪出一个512×512的图像块用于训练，并通过随机翻转和旋转进行数据增强。学习率初始设置为\(10^{-4}\)，在2000个epoch后降至\(10^{-5}\)。训练持续4000个epoch。 

![](https://borninfreedom.github.io/images/2025/01/dark/5.png)
图5. （a）富士X - T2相机在夜间拍摄的图像，感光度ISO为800，光圈f/7.1，曝光时间1/30秒。相机处的照度约为1勒克斯。（b）使用传统流程处理原始数据，无法有效应对数据中的噪声和色彩偏差问题。（c）我们基于相同原始数据得到的处理结果。 
![](https://borninfreedom.github.io/images/2025/01/dark/6.png)
图6. 将在“暗光可视”（SID）数据集上训练的网络应用于iPhone 6s智能手机拍摄的低光照原始图像。(a) 一张由iPhone 6s在夜间拍摄的原始图像，感光度ISO为400，光圈f/2.2，曝光时间0.05秒。该图像经过传统图像处理流程处理，并调整亮度以匹配参考图像。(b) 我们网络的输出结果，放大倍数为100倍。 
![](https://borninfreedom.github.io/images/2025/01/dark/7.png)
图7. 来自索尼300倍放大子集的一张图像。(a) 经传统图像处理流程和线性缩放处理的低光照输入图像。(b) 与(a)相同，但后续进行了BM3D去噪处理。(c) 我们的处理结果。 

![](https://borninfreedom.github.io/images/2025/01/dark/t2.png)
表2. 采用感知实验对比所提出的流程与BM3D和连拍去噪。如文中所述，该实验对基线有利。在所提出的单图像流程在具有挑战性的300倍放大子集上仍显著优于基线，在相对容易的100倍放大子集上与基线表现相当。 

# 5. 实验
## 5.1 定性结果与感知实验
与传统流程对比。我们最初的基线是传统相机处理流程，在量化前进行放大操作（我们使用与我们的流程相同的放大倍数）。图5、图6和图7展示了与该基线的定性对比。在极微光条件下，传统流程生成的图像存在严重的噪声和颜色失真问题。

与去噪和连拍处理对比。自然而然的下一步是对传统流程的输出事后应用现有的去噪算法。近期一项针对真实数据的细致评估表明，在真实图像上，BM3D [7] 的表现优于更新的去噪模型 [32]。因此，我们将BM3D作为参考去噪算法。图7展示了结果。请注意，BM3D是一种非盲去噪方法，需要外部指定噪声水平作为参数。较小的噪声水平设置可能会在图像中留下明显可感知的噪声，而较大的噪声水平设置可能会过度平滑。如图7所示，这两种情况可能在同一图像中同时存在，因为均匀加性噪声并非真实低光照图像的合适模型。相比之下，我们的流程执行盲去噪操作，能够局部适应数据。此外，事后去噪并不能解决传统流程输出中存在的其他伪影，例如颜色失真。

我们还与连拍去噪（burst denoising） [24, 14] 进行对比。由于我们数据集中的图像序列已经对齐，所以与之对比的连拍成像流程是理想化的：它得益于完美对齐，而这在实际中并不存在。因为对齐已经完成，我们通过对8张图像序列取逐像素中位数来进行连拍去噪。
使用参考长曝光图像，从峰值信噪比（PSNR）/ 结构相似性指数（SSIM）方面进行对比，对BM3D和连拍处理并不公平，因为这些基线必须使用经过不同处理的输入图像。为了进行公平对比，我们使用参考图像的白平衡系数来减少颜色偏差。此外，我们逐通道将提供给基线的图像缩放至与参考图像相同的均值。这些调整使得基线生成的图像在颜色和亮度方面外观上更接近参考图像。请注意，这相当于使用先验信息来帮助基线。

为了评估我们的流程、BM3D去噪和连拍去噪所生成图像的相对质量，我们基于在亚马逊Mechanical Turk平台 [4] 上部署的盲随机A/B测试进行了一项感知实验。每次对比都会向一名Mechanical Turk工作人员展示由两种不同流程生成的对应图像，工作人员必须判断哪张图像质量更高。图像对以随机顺序呈现，左右顺序也随机，且不表明不同图像的来源。10名Mechanical Turk工作人员共进行了1180次对比。表2展示了工作人员选择我们所展示流程生成的图像，而非基线之一生成的对应图像的比例。我们使用测试集的两个子集的图像进行了实验：索尼300倍放大（具有挑战性）和索尼100倍放大（相对容易）。在具有挑战性的300倍放大子集上，我们的流程显著优于基线，而在相对容易的100倍放大子集上，与基线表现相当。请记住，由于为基线提供的数据进行了先验预处理，该实验对基线是有利的。还要注意，连拍去噪使用了8张完美对齐图像的信息。

智能手机图像的定性结果。我们预计，为特定相机传感器训练专门的网络时将获得最佳效果。然而，我们关于跨传感器泛化的初步实验表明，这可能并非总是必要的。我们将在SID数据集的索尼子集上训练的模型应用于由iPhone 6s智能手机拍摄的图像，该手机也具有拜耳滤镜阵列和14位原始数据。我们使用一款应用手动设置ISO和其他参数，并导出原始数据进行处理。图6展示了一个具有代表性的结果。由传统流程处理的低光照数据存在严重的噪声和颜色偏移。我们的网络虽然是在来自不同相机的图像上训练的，但其处理结果具有良好的对比度、低噪声和调整得当的颜色。 

![](https://borninfreedom.github.io/images/2025/01/dark/t3.png)


![](https://borninfreedom.github.io/images/2025/01/dark/8.png)
图8. 富士300倍放大测试集中一个图像块在不同网络架构下的对比。(a) 使用多尺度上下文聚合网络（CAN）结构，颜色未正确恢复。(b) 使用U-net。放大查看细节。 

![](https://borninfreedom.github.io/images/2025/01/dark/9.png)
图9. 直方图拉伸的效果。(a) 索尼100倍放大子集中经直方图拉伸处理的参考图像。(b) 在经直方图拉伸处理的图像上训练后得到的输出结果。墙体上出现了伪影。(c) 在未经直方图拉伸处理的图像上训练后得到的输出结果。该结果较暗，但更干净。(d) 对(c)中的图像进行后处理，应用直方图拉伸后的效果。 

![](https://borninfreedom.github.io/images/2025/01/dark/10.png)
图10. 极微光条件下（室内暗室，0.2勒克斯）信号恢复有限。(a) 索尼300倍放大子集中的一张输入图像，经传统流程处理并放大以匹配参考图像。(b) 对(a)应用BM3D去噪后的结果。(c) 利用8张图像进行连拍去噪：由于连拍的所有图像都存在严重伪影，结果仍然不佳。(d) 我们网络的处理结果；仔细查看可明显发现细节有所丢失。 

## 5.2 控制变量实验
表3（第一行）报告了所提出流程在峰值信噪比（PSNR）和结构相似性（SSIM）[38]方面的准确度。现在我们来描述一系列控制变量实验，以评估流程中不同元素的影响。
- **网络结构**：我们首先比较不同的网络架构。表3（第二行）报告了用多尺度上下文聚合网络（CAN）[5]替代U - net[35]（我们的默认架构）的结果。U - net在两个数据集上都有更高的PSNR。尽管CAN生成的图像具有更高的SSIM，但它们有时会出现色彩丢失的情况。图8展示了富士300倍放大子集中的一个图像块，CAN未能正确还原这里的颜色。
- **输入色彩空间**：大多数现有的去噪方法都是对已经过传统图像处理流程处理的sRGB图像进行操作。我们发现，在极微光条件下，直接对原始传感器数据进行操作要有效得多。表3（第三行）展示了将所提出的流程应用于传统流程生成的sRGB图像时的结果。
- **损失函数**：我们默认使用L1损失，但也评估了许多其他损失函数。如表3（第四行和第五行）所示，用L2或SSIM[43]替代L1损失会产生相当的结果。我们没有观察到这些损失函数中的任何一个在感知上有系统性的优势。添加全变分损失并不能提高准确度。添加生成对抗网络（GAN）损失[11]会显著降低准确度。
- **数据排列**：原始传感器数据所有颜色都在单个通道中。为卷积网络排列原始数据的常见选择是将颜色值整合到不同通道中，并相应降低空间分辨率，或者复制和屏蔽不同颜色[10]。我们默认使用整合方式。如表3（第六行）所示，对拜耳数据（索尼子集）进行屏蔽操作得到的PSNR/SSIM比整合方式更低；屏蔽方法的一个典型感知伪影是输出图像中某些色调的丢失。
  
X - Trans数据的结构与拜耳数据非常不同，它以6×6的块排列。一种选择是将其整合到36个通道中。相反，我们通过在相邻元素之间交换一些值来创建一个3×3的模式，然后将其整合到9个通道中。如表3（第七行）所示，6×6的整合方式得到的PSNR/SSIM更低；一个典型的感知伪影是颜色和细节的丢失。
- **后处理**：在最初的实验中，我们在参考图像的处理流程中加入了直方图拉伸。因此，网络除了要学习处理流程的其他部分，还必须学习直方图拉伸。尽管尝试了许多网络架构和损失函数，我们都未能成功训练网络来完成这项任务。如表3（第八行）所示，当对参考图像应用直方图拉伸时（因此网络必须学习直方图拉伸），网络的准确度会显著下降。我们的实验表明，我们的流程不容易学习对整幅图像的全局直方图统计进行建模和操作，并且在面对这项任务时容易过度拟合训练数据。因此，我们将直方图拉伸从流程中去除，并视情况作为后处理应用。图9展示了一个典型结果，尝试学习直方图拉伸会在测试时产生明显的伪影。在未拉伸的参考图像上训练的结果虽然更暗，但更清晰。 

# 6. 讨论
由于光子数量少和信噪比低，快速低光照成像面临巨大挑战。在亚勒克斯光照条件下以视频帧率进行暗光成像，使用传统信号处理技术被认为是不切实际的。在本文中，我们提出了“暗光可视”（SID）数据集，旨在支持开发数据驱动的方法，以实现这种极端条件下的成像。利用SID数据集，我们开发了一种简单的处理流程，相较于传统的低光照图像处理方法有所改进。所提出的流程基于全卷积网络的端到端训练。实验结果令人鼓舞，在SID数据上成功实现了噪声抑制和正确的颜色转换。

这项工作为未来的研究开辟了诸多可能性。我们的研究未涉及高动态范围（HDR）色调映射（注意图1(c)中的饱和区域）。SID数据集存在局限性，它不包含人物和动态物体。所提出流程的结果并不完美，未来的研究工作有望进一步改进，尤其是300倍放大子集极具挑战性。图10(d)展示了该方法输出结果中存在的一些瑕疵。

所提出流程的另一个局限在于，放大倍数必须在外部选定。若能从输入图像中推断出合适的放大倍数，就像自动感光度（Auto ISO）那样，将会很有帮助。此外，我们目前假定针对特定的相机传感器训练专门的网络。我们关于跨传感器泛化的初步实验结果令人振奋，未来的研究可以进一步探索低光照成像网络的泛化能力。

未来研究的另一个方向是运行时优化。所提出的流程处理全分辨率的索尼和富士图像分别需要0.38秒和0.66秒；虽然可以实时生成低分辨率预览，但对于全分辨率的实时处理而言，这个速度还不够快。

我们期待未来的研究能够通过系统地优化网络架构和训练过程等方式，进一步提升图像质量。我们希望SID数据集以及我们的实验发现能够激发并支持此类系统性研究。 